{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Spark IO config\n",
    "\n",
    "In this tutorial, we are trying to explore the spark IO configuration. As we know, spark only focuses on data transformation. The data IO is done by hadoop."
   ],
   "id": "a493596383486e88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:25:39.044861Z",
     "start_time": "2025-07-29T09:25:38.965796Z"
    }
   },
   "cell_type": "code",
   "source": "from pyspark.sql import SparkSession",
   "id": "5ada03972b538d14",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:25:43.522883Z",
     "start_time": "2025-07-29T09:25:39.184116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dir of spark temp file for shuffle, rdd, broadcast\n",
    "spark_temp_dir = \"C:/Users/PLIU/Documents/git/SparkInternals/notebooks/temp/spark_temp\"\n",
    "# dir of hadoop temp file for writing hadoop based file format\n",
    "hadoop_temp_dir = \"C:/Users/PLIU/Documents/git/SparkInternals/notebooks/temp/hadoop_temp\"\n",
    "\n",
    "# create a spark session with custom config\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Explore hadoop fs\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.local.dir\", spark_temp_dir) \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n"
   ],
   "id": "310dcdb6d50791e3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:26:02.623024Z",
     "start_time": "2025-07-29T09:26:02.607036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set hadoop conf\n",
    "\n",
    "hadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "hadoop_conf.set(\"hadoop.tmp.dir\", \"/mnt/ssd1/tmp_hadoop\")"
   ],
   "id": "d604fec9523105c5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Get all default conf value\n",
    "\n",
    "We have two types of conf:\n",
    "- spark conf\n",
    "- SQL conf\n",
    "- spark/hadoop conf\n",
    "\n",
    "### 1.1 Get all spark sql conf\n",
    "\n",
    "`spark.conf` returns a `RuntimeConfig` object. It does not have a getAll method to show all available key-value pairs. You can use the below code to get\n",
    "popular spark sql confs.\n",
    "\n",
    "```python\n",
    "\n",
    "def get_sql_conf(keys: List[str]) -> None:\n",
    "    for key in keys:\n",
    "        value = spark.conf.get(key)\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# popular sql conf keys\n",
    "sql_conf_keys = [\n",
    "    \"spark.sql.shuffle.partitions\",\n",
    "    \"spark.sql.adaptive.enabled\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\",\n",
    "    \"spark.sql.files.maxPartitionBytes\",\n",
    "    \"spark.sql.broadcastTimeout\",\n",
    "    \"spark.sql.autoBroadcastJoinThreshold\"\n",
    "]\n",
    "get_sql_conf(sql_conf_keys)\n",
    "```"
   ],
   "id": "5c7504780f30bb4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:26:22.858038Z",
     "start_time": "2025-07-29T09:26:22.127655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get shuffle partition numbers\n",
    "key = \"spark.sql.shuffle.partitions\"\n",
    "value = spark.conf.get(key)\n",
    "\n",
    "print(f\"{key}: {value}\")"
   ],
   "id": "509472f0cbf20afd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.sql.shuffle.partitions: 8\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:26:25.829408Z",
     "start_time": "2025-07-29T09:26:25.821775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def get_sql_conf(keys: List[str]) -> None:\n",
    "    for key in keys:\n",
    "        value = spark.conf.get(key)\n",
    "        print(f\"{key}: {value}\")"
   ],
   "id": "11a6a4745eaf5737",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:26:28.965243Z",
     "start_time": "2025-07-29T09:26:28.954568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# popular sql conf keys\n",
    "sql_conf_keys = [\n",
    "    \"spark.sql.shuffle.partitions\",\n",
    "    \"spark.sql.adaptive.enabled\",\n",
    "    \"spark.sql.execution.arrow.pyspark.enabled\",\n",
    "    \"spark.sql.files.maxPartitionBytes\",\n",
    "    \"spark.sql.broadcastTimeout\",\n",
    "    \"spark.sql.autoBroadcastJoinThreshold\"\n",
    "]\n",
    "get_sql_conf(sql_conf_keys)"
   ],
   "id": "7929e9f6f9189145",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.sql.shuffle.partitions: 8\n",
      "spark.sql.adaptive.enabled: true\n",
      "spark.sql.execution.arrow.pyspark.enabled: false\n",
      "spark.sql.files.maxPartitionBytes: 134217728b\n",
      "spark.sql.broadcastTimeout: 300000ms\n",
      "spark.sql.autoBroadcastJoinThreshold: 10485760b\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Get spark conf",
   "id": "3243f86e9236b99c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:26:39.773497Z",
     "start_time": "2025-07-29T09:26:39.729093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the spark conf dict\n",
    "spark_conf = spark.sparkContext.getConf()"
   ],
   "id": "f7d528cf9ac73955",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:26:40.328117Z",
     "start_time": "2025-07-29T09:26:40.320483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the spark local dir stores temp date for\n",
    "local_dir = spark_conf.get(\"spark.local.dir\")\n",
    "print(\"default spark.local.dir value=\", local_dir)"
   ],
   "id": "8918db7b96787c42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default spark.local.dir value= C:/Users/PLIU/Documents/git/SparkInternals/notebooks/temp/spark_temp\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:27:40.550177Z",
     "start_time": "2025-07-29T09:27:40.542241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# spark serializer\n",
    "serializer = spark_conf.get(\"spark.serializer\")\n",
    "print(\"default spark.serializer value=\", serializer)"
   ],
   "id": "4e5ea8bee6c35b25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default spark.serializer value= org.apache.spark.serializer.KryoSerializer\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:23:46.165780Z",
     "start_time": "2025-07-29T09:23:46.141994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k, v in spark_conf.getAll():\n",
    "    print(f\"{k} = {v}\")"
   ],
   "id": "b559be1b24ae6a70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.id = local-1753780234380\n",
      "spark.driver.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.driver.memory = 10g\n",
      "spark.app.name = Explore hadoop fs\n",
      "spark.executor.id = driver\n",
      "spark.driver.port = 50499\n",
      "spark.driver.host = LT-5CG4181HBL.casd.me\n",
      "spark.app.submitTime = 1753780232986\n",
      "spark.sql.warehouse.dir = file:/C:/Users/PLIU/Documents/git/SparkInternals/notebooks/spark-warehouse\n",
      "spark.rdd.compress = True\n",
      "spark.executor.extraJavaOptions = -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.serializer.objectStreamReset = 100\n",
      "spark.master = local[*]\n",
      "spark.submit.pyFiles = \n",
      "spark.app.startTime = 1753780233193\n",
      "spark.submit.deployMode = client\n",
      "spark.sql.shuffle.partitions = 8\n",
      "spark.local.dir = C:/Users/PLIU/Documents/git/SparkInternals/notebooks/temp/spark_temp\n",
      "spark.ui.showConsoleProgress = true\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:23:47.699932Z",
     "start_time": "2025-07-29T09:23:47.687677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get default fs\n",
    "hadoop_conf.get(\"fs.defaultFS\")"
   ],
   "id": "93c36945fcb5baba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Below is a list of spark configurations in different categories\n",
    "\n",
    "1. Memory and Resource Allocation\n",
    "2. Disk Spill and Local Temp Directory\n",
    "3. Shuffle and Join Optimization\n",
    "4. Serialization and Format I/O\n",
    "5. Execution & Adaptive Query Execution (AQE)\n",
    "6. Security and Credential Propagation\n",
    "7. Debugging, Logging, and UI\n",
    "8. Misc / Execution Control\n",
    "\n",
    "\n",
    "#### 1.2.1. Memory and Resource Allocation\n",
    "\n",
    "```text\n",
    "spark.driver.memory:\tMemory for driver process (e.g. 4g)\n",
    "spark.executor.memory:\tMemory for each executor (YARN only)\n",
    "spark.memory.fraction:\tFraction of JVM heap used for execution and storage (default: 0.6)\n",
    "spark.memory.storageFraction:\tPortion reserved for caching RDD/DataFrames (default: 0.5)\n",
    "spark.executor.cores:\tCores per executor\n",
    "spark.driver.cores:\tCores used by driver (local mode only)\n",
    "spark.task.cpus:\tThreads per task (default: 1)\n",
    "\n",
    "```\n",
    "\n",
    "#### 1.2.2 Disk Spill and Local Temp Directory\n",
    "\n",
    "```text\n",
    "spark.local.dir:\tWhere Spark stores temp/shuffle data (e.g., /mnt/ssd1/spark)\n",
    "hadoop.tmp.dir:\tHadoop-level temporary directory (used by Hadoop I/O)\n",
    "spark.shuffle.spill.compress:\tCompress spilled shuffle files (true/false)\n",
    "spark.shuffle.spill.numElementsForceSpillThreshold:\tForce spill when element count is reached\n",
    "```\n",
    "\n",
    "#### 1.2.3. Shuffle and Join Optimization\n",
    "```text\n",
    "spark.sql.shuffle.partitions:\tNumber of partitions after shuffles (default: 200)\n",
    "spark.sql.autoBroadcastJoinThreshold:\tMax size (bytes) for auto broadcast joins (default: 10MB)\n",
    "spark.shuffle.compress:\tCompress shuffle data\n",
    "spark.shuffle.file.buffer:\tBuffer size for shuffle file writes (default: 32k)\n",
    "spark.shuffle.sort.bypassMergeThreshold:\tUse bypass merge sort if num partitions ≤ this\n",
    "```\n",
    "#### 1.2.4. Serialization and Format I/O\n",
    "```text\n",
    "spark.serializer:\tClass used to serialize objects (e.g., KryoSerializer)\n",
    "spark.kryo.registrationRequired:\tEnforce class registration for Kryo\n",
    "spark.sql.parquet.compression.codec:\tCompression codec for Parquet (snappy, gzip, lz4)\n",
    "spark.sql.orc.compression.codec:\tORC compression\n",
    "spark.sql.files.maxPartitionBytes:\tBytes per partition when reading files (default: 128MB)\n",
    "```\n",
    "#### 1.2.5. Execution & Adaptive Query Execution (AQE)\n",
    "```text\n",
    "spark.sql.adaptive.enabled:\tEnable AQE (true/false)\n",
    "spark.sql.adaptive.shuffle.targetPostShuffleInputSize:\tTarget partition size for coalescing\n",
    "spark.sql.adaptive.coalescePartitions.enabled:\tAllow AQE to coalesce shuffle partitions\n",
    "spark.sql.adaptive.skewJoin.enabled:\tEnable skew join handling\n",
    "```\n",
    "#### 1.2.6. Security and Credential Propagation\n",
    "```text\n",
    "spark.authenticate:\tEnable Spark internal authentication\n",
    "spark.authenticate.secret:\tShared secret for Spark auth\n",
    "spark.hadoop.fs.s3a.access.key:\tAWS S3 credentials (if needed)\n",
    "spark.hadoop.fs.s3a.secret.key:\tAWS S3 credentials (if needed)\n",
    "spark.hadoop.dfs.client.use.datanode.hostname:\tNeeded for some HDFS setups\n",
    "```\n",
    "#### 1.2.7. Debugging, Logging, and UI\n",
    "```text\n",
    "spark.eventLog.enabled:\tEnable Spark event logging\n",
    "spark.eventLog.dir:\tWhere to store event logs\n",
    "spark.ui.port:\tWeb UI port (default 4040)\n",
    "spark.executor.logs.rolling.strategy:\tRolling log config\n",
    "spark.history.fs.logDirectory:\tSpark History Server config\n",
    "```\n",
    "#### 1.2.8. Misc / Execution Control\n",
    "\n",
    "```text\n",
    "spark.default.parallelism :\tDefault number of partitions (e.g., for RDDs)\n",
    "spark.dynamicAllocation.enabled:\tEnable dynamic executor allocation\n",
    "spark.sql.broadcastTimeout:\tTimeout for broadcast joins (default 300s)\n",
    "spark.cleaner.ttl:\tTTL for cached RDD metadata\n",
    "```\n"
   ],
   "id": "c0259ee8a9c8a253"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:03:32.111400Z",
     "start_time": "2025-07-29T08:03:31.794075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get all available conf default values\n",
    "for entry in hadoop_conf.iterator():\n",
    "    print(f\"{entry.getKey()} = {entry.getValue()}\")"
   ],
   "id": "8f197103a8bac871",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yarn.log-aggregation.file-formats = TFile\n",
      "fs.s3a.select.output.csv.record.delimiter = \\n\n",
      "mapreduce.jobhistory.client.thread-count = 10\n",
      "hadoop.security.group.mapping.ldap.posix.attr.uid.name = uidNumber\n",
      "yarn.admin.acl = *\n",
      "yarn.app.mapreduce.am.job.committer.cancel-timeout = 60000\n",
      "yarn.federation.enabled = false\n",
      "mapreduce.job.emit-timeline-data = false\n",
      "fs.s3a.select.input.csv.quote.character = \"\n",
      "yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions = read\n",
      "yarn.resourcemanager.leveldb-state-store.path = ${hadoop.tmp.dir}/yarn/system/rmstore\n",
      "ipc.client.connection.maxidletime = 10000\n",
      "yarn.nodemanager.health-checker.scripts = script\n",
      "yarn.nodemanager.process-kill-wait.ms = 5000\n",
      "yarn.minicluster.use-rpc = false\n",
      "io.map.index.interval = 128\n",
      "mapreduce.task.profile.reduces = 0-2\n",
      "hadoop.util.hash.type = murmur\n",
      "yarn.webapp.api-service.enable = false\n",
      "yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms = 1000\n",
      "yarn.nodemanager.aux-services.manifest.reload-ms = 0\n",
      "fs.s3a.path.style.access = false\n",
      "fs.AbstractFileSystem.file.impl = org.apache.hadoop.fs.local.LocalFs\n",
      "net.topology.script.number.args = 100\n",
      "yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs = 86400\n",
      "mapreduce.map.output.compress.codec = org.apache.hadoop.io.compress.DefaultCodec\n",
      "yarn.nodemanager.windows-container.memory-limit.enabled = false\n",
      "yarn.timeline-service.webapp.rest-csrf.methods-to-ignore = GET,OPTIONS,HEAD\n",
      "hadoop.security.group.mapping = org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback\n",
      "mapreduce.input.fileinputformat.split.minsize = 0\n",
      "fs.s3a.s3guard.consistency.retry.interval = 2s\n",
      "mapreduce.job.end-notification.max.attempts = 5\n",
      "yarn.nodemanager.runtime.linux.docker.image-update = false\n",
      "mapreduce.reduce.speculative = true\n",
      "hadoop.http.sni.host.check.enabled = false\n",
      "yarn.nodemanager.localizer.cache.cleanup.interval-ms = 600000\n",
      "hadoop.security.auth_to_local.mechanism = hadoop\n",
      "yarn.nodemanager.node-labels.resync-interval-ms = 120000\n",
      "yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size = 10000\n",
      "yarn.resourcemanager.admin.address = ${yarn.resourcemanager.hostname}:8033\n",
      "fs.s3a.metadatastore.fail.on.write.error = true\n",
      "mapreduce.job.maps = 2\n",
      "mapreduce.job.ubertask.enable = false\n",
      "yarn.timeline-service.entity-group-fs-store.retain-seconds = 604800\n",
      "yarn.nodemanager.node-attributes.resync-interval-ms = 120000\n",
      "yarn.app.mapreduce.am.webapp.https.enabled = false\n",
      "mapreduce.am.max-attempts = 2\n",
      "fs.viewfs.overload.scheme.target.gs.impl = com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\n",
      "fs.viewfs.overload.scheme.target.ofs.impl = org.apache.hadoop.fs.ozone.RootedOzoneFileSystem\n",
      "mapreduce.reduce.shuffle.parallelcopies = 5\n",
      "adl.feature.ownerandgroup.enableupn = false\n",
      "mapreduce.job.finish-when-all-reducers-done = true\n",
      "hadoop.registry.zk.retry.ceiling.ms = 60000\n",
      "yarn.nodemanager.env-whitelist = JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ\n",
      "yarn.app.mapreduce.client.job.max-retries = 3\n",
      "yarn.nodemanager.amrmproxy.ha.enable = false\n",
      "fs.s3a.s3guard.ddb.table.capacity.write = 0\n",
      "hadoop.security.key.default.cipher = AES/CTR/NoPadding\n",
      "yarn.nodemanager.linux-container-executor.cgroups.hierarchy = /hadoop-yarn\n",
      "yarn.resourcemanager.recovery.enabled = false\n",
      "yarn.app.mapreduce.am.container.log.backups = 0\n",
      "yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms = 1000\n",
      "yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices = auto\n",
      "fs.s3a.select.input.compression = none\n",
      "yarn.nodemanager.disk-health-checker.interval-ms = 120000\n",
      "yarn.nodemanager.node-labels.provider.fetch-interval-ms = 600000\n",
      "yarn.timeline-service.reader.webapp.address = ${yarn.timeline-service.webapp.address}\n",
      "fs.s3a.max.total.tasks = 32\n",
      "yarn.resourcemanager.resource-tracker.client.thread-count = 50\n",
      "mapreduce.shuffle.port = 13562\n",
      "mapreduce.reduce.maxattempts = 4\n",
      "yarn.resourcemanager.webapp.cross-origin.enabled = false\n",
      "yarn.nodemanager.delete.thread-count = 4\n",
      "yarn.scheduler.configuration.mutation.acl-policy.class = org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy\n",
      "yarn.nodemanager.admin-env = MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX\n",
      "yarn.timeline-service.reader.webapp.https.address = ${yarn.timeline-service.webapp.https.address}\n",
      "mapreduce.job.speculative.speculative-cap-total-tasks = 0.01\n",
      "yarn.resourcemanager.proxy-user-privileges.enabled = false\n",
      "ipc.[port_number].weighted-cost.response = 1\n",
      "ftp.replication = 3\n",
      "mapreduce.job.speculative.slowtaskthreshold = 1.0\n",
      "yarn.sharedcache.cleaner.initial-delay-mins = 10\n",
      "file.bytes-per-checksum = 512\n",
      "mapreduce.task.skip.start.attempts = 2\n",
      "yarn.nodemanager.default-container-executor.log-dirs.permissions = 710\n",
      "hadoop.security.dns.log-slow-lookups.threshold.ms = 1000\n",
      "mapreduce.job.dfs.storage.capacity.kill-limit-exceed = false\n",
      "yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable = false\n",
      "yarn.resourcemanager.placement-constraints.handler = disabled\n",
      "yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size = 10485760\n",
      "yarn.sharedcache.admin.address = 0.0.0.0:8047\n",
      "ipc.[port_number].callqueue.impl = java.util.concurrent.LinkedBlockingQueue\n",
      "yarn.nodemanager.container-log-monitor.enable = false\n",
      "yarn.nodemanager.linux-container-executor.cgroups.mount = false\n",
      "yarn.sharedcache.checksum.algo.impl = org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl\n",
      "fs.s3a.select.output.csv.quote.fields = always\n",
      "mapreduce.job.classloader = false\n",
      "mapreduce.reduce.shuffle.fetch.retry.interval-ms = 1000\n",
      "yarn.resourcemanager.nodemanager.minimum.version = NONE\n",
      "yarn.log-aggregation-enable = false\n",
      "hadoop.security.kms.client.encrypted.key.cache.size = 500\n",
      "yarn.resourcemanager.resource-profiles.enabled = false\n",
      "yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms = 600000\n",
      "mapreduce.output.fileoutputformat.compress.type = RECORD\n",
      "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs = 60\n",
      "yarn.nodemanager.numa-awareness.read-topology = false\n",
      "yarn.nodemanager.log.retain-seconds = 10800\n",
      "yarn.timeline-service.entity-group-fs-store.done-dir = /tmp/entity-file-history/done/\n",
      "fs.viewfs.overload.scheme.target.https.impl = org.apache.hadoop.fs.http.HttpsFileSystem\n",
      "mapreduce.job.end-notification.retry.interval = 1000\n",
      "yarn.nodemanager.local-cache.max-files-per-directory = 8192\n",
      "ha.failover-controller.new-active.rpc-timeout.ms = 60000\n",
      "yarn.nodemanager.resource.memory.enforced = true\n",
      "io.erasurecode.codec.rs-legacy.rawcoders = rs-legacy_java\n",
      "hadoop.ssl.hostname.verifier = DEFAULT\n",
      "hadoop.registry.zk.retry.times = 5\n",
      "yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms = 1000\n",
      "fs.s3a.select.input.csv.header = none\n",
      "mapreduce.fileoutputcommitter.task.cleanup.enabled = false\n",
      "yarn.scheduler.maximum-allocation-mb = 8192\n",
      "mapreduce.task.io.sort.factor = 10\n",
      "yarn.timeline-service.entity-group-fs-store.with-user-dir = false\n",
      "yarn.router.webapp.https.address = 0.0.0.0:8091\n",
      "yarn.resourcemanager.activities-manager.cleanup-interval-ms = 5000\n",
      "mapreduce.outputcommitter.factory.scheme.s3a = org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory\n",
      "yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs = 86400\n",
      "ipc.[port_number].decay-scheduler.decay-factor = 0.5\n",
      "yarn.nodemanager.log.deletion-threads-count = 4\n",
      "ha.health-monitor.rpc-timeout.ms = 45000\n",
      "yarn.resourcemanager.application.max-tags = 10\n",
      "yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users = true\n",
      "fs.AbstractFileSystem.viewfs.impl = org.apache.hadoop.fs.viewfs.ViewFs\n",
      "fs.ftp.host = 0.0.0.0\n",
      "fs.adl.oauth2.access.token.provider.type = ClientCredential\n",
      "yarn.resourcemanager.placement-constraints.algorithm.pool-size = 1\n",
      "yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user = nobody\n",
      "yarn.timeline-service.entity-group-fs-store.active-dir = /tmp/entity-file-history/active\n",
      "fs.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "fs.s3a.s3guard.ddb.background.sleep = 25ms\n",
      "yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs = 86400\n",
      "yarn.resourcemanager.delegation.key.update-interval = 86400000\n",
      "yarn.nodemanager.webapp.https.address = 0.0.0.0:8044\n",
      "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size = 1000\n",
      "io.compression.codec.bzip2.library = system-native\n",
      "mapreduce.map.skip.maxrecords = 0\n",
      "ipc.ping.interval = 60000\n",
      "mapreduce.jobhistory.loadedjobs.cache.size = 5\n",
      "yarn.resourcemanager.application.max-tag.length = 100\n",
      "hadoop.metrics.jvm.use-thread-mxbean = false\n",
      "mapreduce.client.output.filter = FAILED\n",
      "yarn.nodemanager.resource.count-logical-processors-as-cores = false\n",
      "yarn.nodemanager.resource.system-reserved-memory-mb = -1\n",
      "yarn.timeline-service.client.best-effort = false\n",
      "mapreduce.shuffle.pathcache.max-weight = 10485760\n",
      "mapreduce.job.speculative.retry-after-no-speculate = 1000\n",
      "yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled = true\n",
      "io.seqfile.local.dir = ${hadoop.tmp.dir}/io/local\n",
      "yarn.nodemanager.webapp.rest-csrf.methods-to-ignore = GET,OPTIONS,HEAD\n",
      "ha.health-monitor.rpc.connect.max.retries = 1\n",
      "yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min = 3600\n",
      "yarn.app.mapreduce.am.log.level = INFO\n",
      "yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes = runc\n",
      "mapreduce.task.io.sort.mb = 100\n",
      "ipc.[port_number].decay-scheduler.period-ms = 5000\n",
      "yarn.resourcemanager.zk-state-store.parent-path = /rmstore\n",
      "fs.client.resolve.remote.symlinks = true\n",
      "fs.AbstractFileSystem.wasbs.impl = org.apache.hadoop.fs.azure.Wasbs\n",
      "yarn.resourcemanager.nm-container-queuing.min-queue-length = 5\n",
      "hadoop.ssl.enabled.protocols = TLSv1.2\n",
      "yarn.timeline-service.flowname.max-size = 0\n",
      "mapreduce.reduce.cpu.vcores = 1\n",
      "mapreduce.jobhistory.address = 0.0.0.0:10020\n",
      "yarn.client.failover-retries = 0\n",
      "yarn.scheduler.configuration.leveldb-store.compaction-interval-secs = 86400\n",
      "mapreduce.task.local-fs.write-limit.bytes = -1\n",
      "yarn.resourcemanager.configuration.file-system-based-store = /yarn/conf\n",
      "rpc.metrics.timeunit = MILLISECONDS\n",
      "adl.http.timeout = -1\n",
      "mapreduce.job.speculative.retry-after-speculate = 15000\n",
      "yarn.nodemanager.log-aggregation.policy.class = org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy\n",
      "ipc.client.connect.max.retries = 10\n",
      "yarn.nodemanager.container.stderr.tail.bytes = 4096\n",
      "hadoop.security.kms.client.timeout = 60\n",
      "yarn.resourcemanager.reservation-system.planfollower.time-step = 1000\n",
      "yarn.resourcemanager.ha.automatic-failover.embedded = true\n",
      "ipc.server.purge.interval = 15\n",
      "mapreduce.job.heap.memory-mb.ratio = 0.8\n",
      "yarn.nodemanager.log-container-debug-info.enabled = true\n",
      "mapreduce.task.profile.map.params = ${mapreduce.task.profile.params}\n",
      "yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms = 10\n",
      "yarn.resourcemanager.nodemanagers.heartbeat-interval-ms = 1000\n",
      "yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor = 1.0\n",
      "yarn.resourcemanager.keytab = /etc/krb5.keytab\n",
      "yarn.nodemanager.runtime.linux.sandbox-mode = disabled\n",
      "yarn.nodemanager.aux-services.manifest.enabled = false\n",
      "yarn.cluster.max-application-priority = 0\n",
      "fs.viewfs.overload.scheme.target.file.impl = org.apache.hadoop.fs.LocalFileSystem\n",
      "yarn.log-aggregation-status.time-out.ms = 600000\n",
      "yarn.federation.state-store.class = org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore\n",
      "yarn.client.max-cached-nodemanagers-proxies = 0\n",
      "fs.trash.checkpoint.interval = 0\n",
      "yarn.sharedcache.app-checker.class = org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker\n",
      "yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage = 90.0\n",
      "yarn.app.mapreduce.am.staging-dir = /tmp/hadoop-yarn/staging\n",
      "yarn.nm.liveness-monitor.expiry-interval-ms = 600000\n",
      "mapreduce.reduce.shuffle.merge.percent = 0.66\n",
      "fs.s3a.select.enabled = true\n",
      "yarn.nodemanager.health-checker.timeout-ms = 1200000\n",
      "ipc.client.connect.timeout = 20000\n",
      "ipc.[port_number].weighted-cost.lockexclusive = 100\n",
      "yarn.nodemanager.local-dirs = ${hadoop.tmp.dir}/nm-local-dir\n",
      "yarn.scheduler.configuration.store.class = file\n",
      "fs.s3a.committer.staging.tmp.path = tmp/staging\n",
      "yarn.nodemanager.recovery.enabled = false\n",
      "yarn.resourcemanager.am.max-attempts = 2\n",
      "yarn.timeline-service.client.internal-timers-ttl-secs = 420\n",
      "yarn.nodemanager.resource.pcores-vcores-multiplier = 1.0\n",
      "hadoop.kerberos.min.seconds.before.relogin = 60\n",
      "yarn.app.attempt.diagnostics.limit.kc = 64\n",
      "hadoop.security.group.mapping.ldap.ssl = false\n",
      "fs.defaultFS = file:///\n",
      "hadoop.security.group.mapping.ldap.search.attr.group.name = cn\n",
      "yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage = 90.0\n",
      "yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled = false\n",
      "fs.viewfs.overload.scheme.target.swebhdfs.impl = org.apache.hadoop.hdfs.web.SWebHdfsFileSystem\n",
      "yarn.router.pipeline.cache-max-size = 25\n",
      "mapreduce.map.sort.spill.percent = 0.80\n",
      "yarn.log-aggregation.file-controller.TFile.class = org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController\n",
      "yarn.webapp.filter-entity-list-by-user = false\n",
      "hadoop.security.crypto.codec.classes.aes.ctr.nopadding = org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec\n",
      "fs.s3a.metadatastore.impl = org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore\n",
      "hadoop.security.groups.negative-cache.secs = 30\n",
      "hadoop.ssl.server.conf = ssl-server.xml\n",
      "yarn.client.nodemanager-client-async.thread-pool-max-size = 500\n",
      "yarn.minicluster.yarn.nodemanager.resource.memory-mb = 4096\n",
      "mapreduce.jobhistory.admin.address = 0.0.0.0:10033\n",
      "fs.s3a.connection.request.timeout = 0\n",
      "yarn.nodemanager.health-checker.interval-ms = 600000\n",
      "ftp.client-write-packet-size = 65536\n",
      "yarn.timeline-service.keytab = /etc/krb5.keytab\n",
      "mapreduce.reduce.shuffle.fetch.retry.enabled = ${yarn.nodemanager.recovery.enabled}\n",
      "yarn.app.mapreduce.task.container.log.backups = 0\n",
      "ha.zookeeper.session-timeout.ms = 10000\n",
      "hadoop.security.key.default.bitlength = 128\n",
      "hadoop.http.authentication.signature.secret.file = ${user.home}/hadoop-http-auth-signature-secret\n",
      "mapreduce.jobhistory.webapp.xfs-filter.xframe-options = SAMEORIGIN\n",
      "yarn.nodemanager.log-aggregation.compression-type = none\n",
      "yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms = 10000\n",
      "yarn.nodemanager.log-dirs = ${yarn.log.dir}/userlogs\n",
      "yarn.nodemanager.container-retry-minimum-interval-ms = 1000\n",
      "mapreduce.job.speculative.minimum-allowed-tasks = 10\n",
      "yarn.node-attribute.fs-store.impl.class = org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore\n",
      "mapreduce.jobhistory.recovery.store.class = org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService\n",
      "mapreduce.task.combine.progress.records = 10000\n",
      "yarn.nodemanager.recovery.supervised = false\n",
      "yarn.nodemanager.amrmproxy.interceptor-class.pipeline = org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor\n",
      "ipc.client.low-latency = false\n",
      "yarn.nodemanager.address = ${yarn.nodemanager.hostname}:0\n",
      "yarn.webapp.enable-rest-app-submissions = true\n",
      "mapreduce.job.reduces = 1\n",
      "yarn.scheduler.queue-placement-rules = user-group\n",
      "hadoop.security.kms.client.encrypted.key.cache.expiry = 43200000\n",
      "yarn.resourcemanager.configuration.provider-class = org.apache.hadoop.yarn.LocalConfigurationProvider\n",
      "yarn.timeline-service.address = ${yarn.timeline-service.hostname}:10200\n",
      "yarn.sharedcache.enabled = false\n",
      "hadoop.registry.zk.session.timeout.ms = 60000\n",
      "tfile.io.chunk.size = 1048576\n",
      "ha.health-monitor.sleep-after-disconnect.ms = 1000\n",
      "yarn.timeline-service.http-cross-origin.enabled = false\n",
      "fs.azure.user.agent.prefix = unknown\n",
      "yarn.router.interceptor.user.threadpool-size = 5\n",
      "yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs = 20\n",
      "hadoop.http.authentication.token.validity = 36000\n",
      "ha.failover-controller.graceful-fence.rpc-timeout.ms = 5000\n",
      "mapreduce.jobhistory.cleaner.interval-ms = 86400000\n",
      "yarn.resourcemanager.application-tag-based-placement.enable = false\n",
      "yarn.nodemanager.opportunistic-containers-max-queue-length = 0\n",
      "yarn.resourcemanager.reservation-system.enable = false\n",
      "hadoop.security.crypto.buffer.size = 8192\n",
      "mapreduce.reduce.shuffle.read.timeout = 180000\n",
      "fs.ftp.transfer.mode = BLOCK_TRANSFER_MODE\n",
      "fs.s3a.executor.capacity = 16\n",
      "mapreduce.ifile.readahead.bytes = 4194304\n",
      "hadoop.registry.secure = false\n",
      "yarn.nodemanager.resource-plugins.gpu.docker-plugin = nvidia-docker-v1\n",
      "fs.wasb.impl = org.apache.hadoop.fs.azure.NativeAzureFileSystem\n",
      "fs.viewfs.overload.scheme.target.http.impl = org.apache.hadoop.fs.http.HttpFileSystem\n",
      "yarn.timeline-service.http-authentication.type = simple\n",
      "hadoop.prometheus.endpoint.enabled = false\n",
      "ipc.client.bind.wildcard.addr = false\n",
      "yarn.dispatcher.drain-events.timeout = 300000\n",
      "yarn.log-aggregation.retain-seconds = -1\n",
      "mapreduce.job.complete.cancel.delegation.tokens = true\n",
      "fs.s3a.multiobjectdelete.enable = true\n",
      "yarn.resourcemanager.fail-fast = ${yarn.fail-fast}\n",
      "yarn.resourcemanager.resource-profiles.source-file = resource-profiles.json\n",
      "mapreduce.shuffle.connection-keep-alive.timeout = 5\n",
      "yarn.resourcemanager.placement-constraints.retry-attempts = 3\n",
      "yarn.scheduler.minimum-allocation-vcores = 1\n",
      "ipc.[port_number].weighted-cost.handler = 1\n",
      "fs.s3a.s3guard.ddb.throttle.retry.interval = 100ms\n",
      "yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed = false\n",
      "yarn.timeline-service.client.max-retries = 30\n",
      "yarn.timeline-service.client.retry-interval-ms = 1000\n",
      "nfs.exports.allowed.hosts = * rw\n",
      "mapreduce.shuffle.max.threads = 0\n",
      "io.file.buffer.size = 65536\n",
      "yarn.nodemanager.container-metrics.unregister-delay-ms = 10000\n",
      "hadoop.security.secure.random.impl = org.apache.hadoop.crypto.random.OpensslSecureRandom\n",
      "ipc.client.connect.retry.interval = 1000\n",
      "fs.viewfs.overload.scheme.target.hdfs.impl = org.apache.hadoop.hdfs.DistributedFileSystem\n",
      "mapreduce.reduce.shuffle.connect.timeout = 180000\n",
      "yarn.nodemanager.container-metrics.period-ms = -1\n",
      "yarn.resourcemanager.fs.state-store.uri = ${hadoop.tmp.dir}/yarn/system/rmstore\n",
      "yarn.timeline-service.client.drain-entities.timeout.ms = 2000\n",
      "hadoop.registry.zk.connection.timeout.ms = 15000\n",
      "fs.AbstractFileSystem.adl.impl = org.apache.hadoop.fs.adl.Adl\n",
      "fs.AbstractFileSystem.wasb.impl = org.apache.hadoop.fs.azure.Wasb\n",
      "yarn.timeline-service.client.fd-flush-interval-secs = 10\n",
      "yarn.app.mapreduce.am.container.log.limit.kb = 0\n",
      "yarn.nodemanager.resourcemanager.minimum.version = NONE\n",
      "yarn.resourcemanager.address = ${yarn.resourcemanager.hostname}:8032\n",
      "file.stream-buffer-size = 4096\n",
      "ipc.[port_number].identity-provider.impl = org.apache.hadoop.ipc.UserIdentityProvider\n",
      "mapreduce.job.ubertask.maxreduces = 1\n",
      "yarn.resourcemanager.nodemanager-connect-retries = 10\n",
      "fs.azure.secure.mode = false\n",
      "hadoop.security.group.mapping.ldap.search.group.hierarchy.levels = 0\n",
      "ipc.client.idlethreshold = 4000\n",
      "yarn.nodemanager.logaggregation.threadpool-size-max = 100\n",
      "yarn.nodemanager.collector-service.address = ${yarn.nodemanager.hostname}:8048\n",
      "fs.abfss.impl = org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem\n",
      "ftp.stream-buffer-size = 4096\n",
      "yarn.sharedcache.client-server.address = 0.0.0.0:8045\n",
      "fs.ftp.timeout = 0\n",
      "hadoop.http.authentication.simple.anonymous.allowed = true\n",
      "yarn.client.nodemanager-connect.retry-interval-ms = 10000\n",
      "yarn.timeline-service.webapp.rest-csrf.custom-header = X-XSRF-Header\n",
      "yarn.nodemanager.linux-container-executor.resources-handler.class = org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler\n",
      "yarn.timeline-service.leveldb-timeline-store.read-cache-size = 104857600\n",
      "yarn.timeline-service.app-collector.linger-period.ms = 60000\n",
      "hadoop.security.authentication = simple\n",
      "mapreduce.task.files.preserve.failedtasks = false\n",
      "yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds = 259200000\n",
      "mapreduce.reduce.skip.proc-count.auto-incr = true\n",
      "file.replication = 1\n",
      "yarn.nodemanager.amrmproxy.client.thread-count = 25\n",
      "yarn.federation.cache-ttl.secs = 300\n",
      "mapreduce.jobhistory.joblist.cache.size = 20000\n",
      "ipc.server.reuseaddr = true\n",
      "yarn.nodemanager.runtime.linux.docker.stop.grace-period = 10\n",
      "yarn.resourcemanager.work-preserving-recovery.enabled = true\n",
      "fs.s3a.multipart.purge = false\n",
      "fs.getspaceused.jitterMillis = 60000\n",
      "yarn.resourcemanager.webapp.ui-actions.enabled = true\n",
      "fs.s3a.connection.establish.timeout = 5000\n",
      "yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb = 0\n",
      "yarn.rm.system-metrics-publisher.emit-container-events = false\n",
      "yarn.resourcemanager.proxy.timeout.enabled = true\n",
      "fs.s3a.downgrade.syncable.exceptions = true\n",
      "fs.s3a.multipart.purge.age = 86400\n",
      "yarn.resourcemanager.scheduler.client.thread-count = 50\n",
      "yarn.resourcemanager.auto-update.containers = false\n",
      "yarn.scheduler.configuration.leveldb-store.path = ${hadoop.tmp.dir}/yarn/system/confstore\n",
      "ipc.maximum.data.length = 134217728\n",
      "tfile.fs.input.buffer.size = 262144\n",
      "yarn.resourcemanager.webapp.rest-csrf.enabled = false\n",
      "hadoop.http.authentication.type = simple\n",
      "mapreduce.map.cpu.vcores = 1\n",
      "yarn.nodemanager.numa-awareness.enabled = false\n",
      "yarn.resourcemanager.zk-delegation-token-node.split-index = 0\n",
      "fs.AbstractFileSystem.webhdfs.impl = org.apache.hadoop.fs.WebHdfs\n",
      "yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs = 360\n",
      "ftp.bytes-per-checksum = 512\n",
      "hadoop.workaround.non.threadsafe.getpwuid = true\n",
      "yarn.nodemanager.elastic-memory-control.timeout-sec = 5\n",
      "ipc.[port_number].scheduler.priority.levels = 4\n",
      "yarn.nodemanager.pmem-check-enabled = true\n",
      "mapreduce.task.profile.maps = 0-2\n",
      "mapreduce.shuffle.ssl.file.buffer.size = 65536\n",
      "yarn.timeline-service.webapp.https.address = ${yarn.timeline-service.hostname}:8190\n",
      "fs.abfs.impl = org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem\n",
      "yarn.registry.class = org.apache.hadoop.registry.client.impl.FSRegistryOperationsService\n",
      "yarn.nodemanager.resource.memory.enabled = false\n",
      "yarn.app.mapreduce.am.command-opts = -Xmx1024m\n",
      "fs.viewfs.overload.scheme.target.swift.impl = org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem\n",
      "yarn.resourcemanager.amlauncher.thread-count = 50\n",
      "yarn.timeline-service.timeline-client.number-of-async-entities-to-merge = 10\n",
      "dfs.client.ignore.namenode.default.kms.uri = false\n",
      "yarn.sharedcache.nm.uploader.replication.factor = 10\n",
      "yarn.nodemanager.node-attributes.provider.fetch-interval-ms = 600000\n",
      "yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat = -1\n",
      "hadoop.registry.zk.root = /registry\n",
      "yarn.client.failover-proxy-provider = org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider\n",
      "yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts = 10\n",
      "yarn.timeline-service.client.fd-retain-secs = 300\n",
      "hadoop.caller.context.max.size = 128\n",
      "yarn.nodemanager.amrmproxy.enabled = false\n",
      "hadoop.http.cross-origin.max-age = 1800\n",
      "yarn.nodemanager.remote-app-log-dir-suffix = logs\n",
      "mapreduce.jobhistory.principal = jhs/_HOST@REALM.TLD\n",
      "mapreduce.reduce.merge.inmem.threshold = 1000\n",
      "fs.s3a.select.input.csv.record.delimiter = \\n\n",
      "fs.s3a.metadatastore.metadata.ttl = 15m\n",
      "fs.s3a.accesspoint.required = false\n",
      "fs.s3a.retry.limit = 7\n",
      "mapreduce.job.queuename = default\n",
      "mapreduce.jobhistory.max-age-ms = 604800000\n",
      "fs.azure.authorization = false\n",
      "yarn.nodemanager.localizer.client.thread-count = 5\n",
      "yarn.sharedcache.uploader.server.thread-count = 50\n",
      "fs.s3a.s3guard.ddb.table.sse.enabled = false\n",
      "ipc.client.rpc-timeout.ms = 0\n",
      "mapreduce.task.profile.params = -agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s\n",
      "mapreduce.jobhistory.datestring.cache.size = 200000\n",
      "fs.s3a.committer.name = file\n",
      "yarn.acl.reservation-enable = false\n",
      "io.bytes.per.checksum = 512\n",
      "mapreduce.jobhistory.loadedjob.tasks.max = -1\n",
      "fs.azure.local.sas.key.mode = false\n",
      "yarn.app.mapreduce.client.max-retries = 3\n",
      "yarn.client.failover-no-ha-proxy-provider = org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider\n",
      "yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed = false\n",
      "yarn.node-labels.enabled = false\n",
      "ipc.server.listen.queue.size = 256\n",
      "fs.s3a.threads.max = 64\n",
      "yarn.timeline-service.handler-thread-count = 10\n",
      "yarn.resourcemanager.connect.max-wait.ms = 900000\n",
      "yarn.nodemanager.resource.detect-hardware-capabilities = false\n",
      "yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size = 10\n",
      "yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes = runc\n",
      "mapreduce.job.max.split.locations = 15\n",
      "yarn.resourcemanager.scheduler.class = org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler\n",
      "yarn.is.minicluster = false\n",
      "fs.s3a.threads.keepalivetime = 60\n",
      "mapreduce.shuffle.connection-keep-alive.enable = false\n",
      "hadoop.security.groups.shell.command.timeout = 0s\n",
      "yarn.nodemanager.disk-validator = basic\n",
      "ha.failover-controller.cli-check.rpc-timeout.ms = 20000\n",
      "ha.zookeeper.acl = world:anyone:rwcda\n",
      "mapreduce.input.lineinputformat.linespermap = 1\n",
      "yarn.nodemanager.localizer.fetch.thread-count = 4\n",
      "yarn.resourcemanager.scheduler.address = ${yarn.resourcemanager.hostname}:8030\n",
      "yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size = 10000\n",
      "ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds = 10s,20s,30s,40s\n",
      "hadoop.service.shutdown.timeout = 30s\n",
      "mapreduce.shuffle.ssl.enabled = false\n",
      "mapreduce.reduce.log.level = INFO\n",
      "yarn.resourcemanager.delegation-token.max-conf-size-bytes = 12800\n",
      "mapreduce.job.cache.limit.max-resources-mb = 0\n",
      "yarn.resourcemanager.opportunistic-container-allocation.nodes-used = 10\n",
      "yarn.nodemanager.log-aggregation.num-log-files-per-app = 30\n",
      "yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size = 10\n",
      "yarn.resourcemanager.ha.enabled = false\n",
      "yarn.dispatcher.cpu-monitor.samples-per-min = 60\n",
      "fs.viewfs.overload.scheme.target.abfs.impl = org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem\n",
      "fs.s3a.select.input.csv.quote.escape.character = \\\\\n",
      "fs.s3a.multipart.threshold = 128M\n",
      "mapreduce.reduce.shuffle.memory.limit.percent = 0.25\n",
      "hadoop.http.cross-origin.enabled = false\n",
      "yarn.scheduler.include-port-in-node-name = false\n",
      "yarn.workflow-id.tag-prefix = workflowid:\n",
      "yarn.resourcemanager.state-store.max-completed-applications = ${yarn.resourcemanager.max-completed-applications}\n",
      "yarn.resourcemanager.application-https.policy = NONE\n",
      "yarn.nodemanager.resource.memory.cgroups.swappiness = 0\n",
      "fs.s3a.ssl.channel.mode = default_jsse\n",
      "map.sort.class = org.apache.hadoop.util.QuickSort\n",
      "fs.s3a.change.detection.mode = server\n",
      "fs.s3a.buffer.dir = ${hadoop.tmp.dir}/s3a\n",
      "mapreduce.reduce.shuffle.retry-delay.max.ms = 60000\n",
      "yarn.resourcemanager.zk-max-znode-size.bytes = 1048576\n",
      "yarn.app.mapreduce.shuffle.log.limit.kb = 0\n",
      "mapreduce.client.progressmonitor.pollinterval = 1000\n",
      "dfs.ha.fencing.ssh.connect-timeout = 30000\n",
      "mapreduce.jobhistory.move.interval-ms = 180000\n",
      "yarn.timeline-service.hbase-schema.prefix = prod.\n",
      "yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds = -1\n",
      "yarn.timeline-service.state-store-class = org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore\n",
      "hadoop.security.crypto.cipher.suite = AES/CTR/NoPadding\n",
      "fs.s3a.fast.upload.active.blocks = 4\n",
      "yarn.resourcemanager.opportunistic-container-allocation.enabled = false\n",
      "yarn.timeline-service.generic-application-history.max-applications = 10000\n",
      "hadoop.registry.jaas.context = Client\n",
      "yarn.resourcemanager.hostname = 0.0.0.0\n",
      "hadoop.security.group.mapping.ldap.search.filter.group = (objectClass=group)\n",
      "ipc.[port_number].weighted-cost.lockshared = 10\n",
      "hadoop.shell.safely.delete.limit.num.files = 100\n",
      "hadoop.security.group.mapping.ldap.search.filter.user = (&(objectClass=user)(sAMAccountName={0}))\n",
      "yarn.client.failover-retries-on-socket-timeouts = 0\n",
      "mapreduce.shuffle.pathcache.expire-after-access-minutes = 5\n",
      "ipc.server.log.slow.rpc = false\n",
      "mapreduce.jobhistory.recovery.store.leveldb.path = ${hadoop.tmp.dir}/mapred/history/recoverystore\n",
      "yarn.sharedcache.store.class = org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore\n",
      "yarn.app.mapreduce.am.webapp.https.client.auth = false\n",
      "yarn.nodemanager.windows-container.cpu-limit.enabled = false\n",
      "fs.viewfs.overload.scheme.target.ftp.impl = org.apache.hadoop.fs.ftp.FTPFileSystem\n",
      "ipc.[port_number].decay-scheduler.backoff.responsetime.enable = false\n",
      "yarn.nodemanager.vmem-pmem-ratio = 2.1\n",
      "yarn.nodemanager.node-labels.provider.fetch-timeout-ms = 1200000\n",
      "yarn.timeline-service.hbase.coprocessor.jar.hdfs.location = /hbase/coprocessor/hadoop-yarn-server-timelineservice.jar\n",
      "yarn.resourcemanager.scheduler.monitor.policies = org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy\n",
      "yarn.router.webapp.interceptor-class.pipeline = org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST\n",
      "io.erasurecode.codec.rs.rawcoders = rs_native,rs_java\n",
      "yarn.resourcemanager.delegation-token-renewer.thread-retry-interval = 60s\n",
      "yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed = true\n",
      "yarn.resourcemanager.leveldb-state-store.compaction-interval-secs = 3600\n",
      "yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size = 10\n",
      "yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds = 3600\n",
      "yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold = 1\n",
      "fs.s3a.block.size = 32M\n",
      "fs.ftp.host.port = 21\n",
      "mapreduce.job.end-notification.retry.attempts = 0\n",
      "yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms = 300000\n",
      "yarn.nodemanager.runtime.linux.allowed-runtimes = default\n",
      "yarn.ipc.rpc.class = org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC\n",
      "mapreduce.cluster.acls.enabled = false\n",
      "yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices = auto\n",
      "mapreduce.job.encrypted-intermediate-data-key-size-bits = 128\n",
      "mapreduce.job.ubertask.maxmaps = 9\n",
      "yarn.nodemanager.runtime.linux.docker.default-container-network = host\n",
      "yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled = true\n",
      "yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold = 1\n",
      "yarn.nodemanager.container-manager.thread-count = 20\n",
      "fs.s3a.metadatastore.authoritative = false\n",
      "mapreduce.app-submission.cross-platform = false\n",
      "mapreduce.job.reducer.preempt.delay.sec = 0\n",
      "yarn.timeline-service.entity-group-fs-store.cache-store-class = org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore\n",
      "mapreduce.reduce.markreset.buffer.percent = 0.0\n",
      "yarn.nodemanager.node-attributes.provider.fetch-timeout-ms = 1200000\n",
      "hadoop.security.group.mapping.ldap.num.attempts = 3\n",
      "yarn.scheduler.configuration.fs.path = file://${hadoop.tmp.dir}/yarn/system/schedconf\n",
      "fs.viewfs.overload.scheme.target.o3fs.impl = org.apache.hadoop.fs.ozone.OzoneFileSystem\n",
      "fs.AbstractFileSystem.abfss.impl = org.apache.hadoop.fs.azurebfs.Abfss\n",
      "mapreduce.jobhistory.recovery.store.fs.uri = ${hadoop.tmp.dir}/mapred/history/recoverystore\n",
      "yarn.nodemanager.webapp.xfs-filter.xframe-options = SAMEORIGIN\n",
      "hadoop.registry.zk.retry.interval.ms = 1000\n",
      "yarn.nodemanager.keytab = /etc/krb5.keytab\n",
      "yarn.timeline-service.webapp.xfs-filter.xframe-options = SAMEORIGIN\n",
      "yarn.nodemanager.delete.debug-delay-sec = 0\n",
      "yarn.timeline-service.ttl-enable = true\n",
      "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file = /runc-root/image-tag-to-hash\n",
      "mapreduce.reduce.skip.maxgroups = 0\n",
      "fs.trash.interval = 0\n",
      "fs.s3a.change.detection.version.required = true\n",
      "ipc.[port_number].decay-scheduler.metrics.top.user.count = 10\n",
      "yarn.nodemanager.container-log-monitor.interval-ms = 60000\n",
      "seq.io.sort.factor = 100\n",
      "yarn.nodemanager.resource-monitor.interval-ms = 3000\n",
      "fs.s3a.select.output.csv.field.delimiter = ,\n",
      "fs.s3a.s3guard.consistency.retry.limit = 7\n",
      "mapreduce.job.local-fs.single-disk-limit.check.interval-ms = 5000\n",
      "seq.io.sort.mb = 100\n",
      "hadoop.security.instrumentation.requires.admin = false\n",
      "mapreduce.jobhistory.done-dir = ${yarn.app.mapreduce.am.staging-dir}/history/done\n",
      "yarn.resourcemanager.container.liveness-monitor.interval-ms = 600000\n",
      "fs.s3a.committer.staging.conflict-mode = append\n",
      "mapreduce.jobhistory.cleaner.enable = true\n",
      "mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore = GET,OPTIONS,HEAD\n",
      "ha.failover-controller.graceful-fence.connection.retries = 1\n",
      "yarn.nodemanager.remote-app-log-dir-include-older = true\n",
      "yarn.nodemanager.disk-health-checker.enable = true\n",
      "yarn.nodemanager.container-monitor.enabled = true\n",
      "hadoop.security.java.secure.random.algorithm = SHA1PRNG\n",
      "mapreduce.client.submit.file.replication = 10\n",
      "yarn.fail-fast = false\n",
      "yarn.resourcemanager.placement-constraints.algorithm.class = org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm\n",
      "io.skip.checksum.errors = false\n",
      "yarn.timeline-service.hostname = 0.0.0.0\n",
      "yarn.resourcemanager.nm-container-queuing.load-comparator = QUEUE_LENGTH\n",
      "yarn.acl.enable = false\n",
      "yarn.nodemanager.emit-container-events = true\n",
      "file.blocksize = 67108864\n",
      "yarn.timeline-service.writer.async.queue.capacity = 100\n",
      "hadoop.rpc.socket.factory.class.default = org.apache.hadoop.net.StandardSocketFactory\n",
      "yarn.resourcemanager.delegation-token-renewer.thread-count = 50\n",
      "fs.AbstractFileSystem.swebhdfs.impl = org.apache.hadoop.fs.SWebHdfs\n",
      "io.erasurecode.codec.xor.rawcoders = xor_native,xor_java\n",
      "yarn.resourcemanager.application-timeouts.monitor.interval-ms = 3000\n",
      "hadoop.common.configuration.version = 3.0.0\n",
      "yarn.resourcemanager.client.thread-count = 50\n",
      "fs.azure.buffer.dir = ${hadoop.tmp.dir}/abfs\n",
      "yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern = ^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$\n",
      "yarn.resourcemanager.max-completed-applications = 1000\n",
      "yarn.sharedcache.cleaner.period-mins = 1440\n",
      "yarn.federation.registry.base-dir = yarnfederation/\n",
      "mapreduce.job.end-notification.max.retry.interval = 5000\n",
      "yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed = false\n",
      "mapreduce.jobhistory.always-scan-user-dir = false\n",
      "yarn.resourcemanager.delegation-token.always-cancel = false\n",
      "mapreduce.job.acl-view-job =  \n",
      "yarn.app.mapreduce.am.job.task.listener.thread-count = 30\n",
      "yarn.app.mapreduce.am.resource.cpu-vcores = 1\n",
      "mapreduce.map.skip.proc-count.auto-incr = true\n",
      "hadoop.security.group.mapping.ldap.search.attr.member = member\n",
      "yarn.resourcemanager.placement-constraints.algorithm.iterator = SERIAL\n",
      "fs.viewfs.overload.scheme.target.webhdfs.impl = org.apache.hadoop.hdfs.web.WebHdfsFileSystem\n",
      "hadoop.ssl.client.conf = ssl-client.xml\n",
      "fs.s3a.select.output.csv.quote.escape.character = \\\\\n",
      "yarn.sharedcache.root-dir = /sharedcache\n",
      "hadoop.security.groups.cache.background.reload = false\n",
      "mapreduce.reduce.shuffle.fetch.retry.timeout-ms = 30000\n",
      "hadoop.security.credential.clear-text-fallback = true\n",
      "mapreduce.map.memory.mb = -1\n",
      "yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs = 600\n",
      "fs.viewfs.overload.scheme.target.s3a.impl = org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "mapreduce.jobhistory.jhist.format = binary\n",
      "yarn.resourcemanager.connect.retry-interval.ms = 30000\n",
      "yarn.timeline-service.webapp.address = ${yarn.timeline-service.hostname}:8188\n",
      "yarn.scheduler.minimum-allocation-mb = 1024\n",
      "net.topology.impl = org.apache.hadoop.net.NetworkTopology\n",
      "yarn.sharedcache.cleaner.resource-sleep-ms = 0\n",
      "ipc.[port_number].weighted-cost.lockfree = 1\n",
      "io.seqfile.compress.blocksize = 1000000\n",
      "fs.AbstractFileSystem.ftp.impl = org.apache.hadoop.fs.ftp.FtpFs\n",
      "ha.failover-controller.active-standby-elector.zk.op.retries = 3\n",
      "mapreduce.job.running.reduce.limit = 0\n",
      "mapreduce.job.reduce.shuffle.consumer.plugin.class = org.apache.hadoop.mapreduce.task.reduce.Shuffle\n",
      "ipc.[port_number].faircallqueue.multiplexer.weights = 8,4,2,1\n",
      "yarn.nodemanager.vmem-check-enabled = true\n",
      "hadoop.rpc.protection = authentication\n",
      "fs.permissions.umask-mode = 022\n",
      "hadoop.http.staticuser.user = dr.who\n",
      "fs.s3a.list.version = 2\n",
      "fs.s3a.connection.maximum = 96\n",
      "fs.s3a.paging.maximum = 5000\n",
      "yarn.resourcemanager.delegation.token.renew-interval = 86400000\n",
      "ipc.maximum.response.length = 134217728\n",
      "hadoop.shell.missing.defaultFs.warning = false\n",
      "ipc.[port_number].scheduler.impl = org.apache.hadoop.ipc.DefaultRpcScheduler\n",
      "hadoop.http.authentication.kerberos.keytab = ${user.home}/hadoop.keytab\n",
      "yarn.nodemanager.container-localizer.java.opts = -Xmx256m\n",
      "fs.azure.saskey.usecontainersaskeyforallaccess = true\n",
      "mapreduce.job.maxtaskfailures.per.tracker = 3\n",
      "mapreduce.shuffle.max.connections = 0\n",
      "net.topology.node.switch.mapping.impl = org.apache.hadoop.net.ScriptBasedMapping\n",
      "hadoop.kerberos.keytab.login.autorenewal.enabled = false\n",
      "yarn.nodemanager.runtime.linux.runc.allowed-container-networks = host,none,bridge\n",
      "yarn.client.application-client-protocol.poll-interval-ms = 200\n",
      "yarn.nodemanager.localizer.address = ${yarn.nodemanager.hostname}:8040\n",
      "mapreduce.shuffle.pathcache.concurrency-level = 16\n",
      "fs.viewfs.overload.scheme.target.oss.impl = org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem\n",
      "fs.s3a.readahead.range = 64K\n",
      "ha.zookeeper.parent-znode = /hadoop-ha\n",
      "yarn.sharedcache.admin.thread-count = 1\n",
      "yarn.nodemanager.resource.cpu-vcores = -1\n",
      "mapreduce.jobhistory.http.policy = HTTP_ONLY\n",
      "fs.s3a.attempts.maximum = 20\n",
      "yarn.log-aggregation.retain-check-interval-seconds = -1\n",
      "fs.viewfs.overload.scheme.target.wasb.impl = org.apache.hadoop.fs.azure.NativeAzureFileSystem\n",
      "mapreduce.jobhistory.intermediate-user-done-dir.permissions = 770\n",
      "yarn.resourcemanager.node-ip-cache.expiry-interval-secs = -1\n",
      "fs.wasbs.impl = org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure\n",
      "yarn.timeline-service.client.fd-clean-interval-secs = 60\n",
      "hadoop.ssl.keystores.factory.class = org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory\n",
      "hadoop.zk.num-retries = 1000\n",
      "mapreduce.job.split.metainfo.maxsize = 10000000\n",
      "hadoop.security.random.device.file.path = /dev/urandom\n",
      "yarn.client.nodemanager-connect.max-wait-ms = 180000\n",
      "yarn.app.mapreduce.client-am.ipc.max-retries = 3\n",
      "yarn.nodemanager.container-diagnostics-maximum-size = 10000\n",
      "ipc.[port_number].decay-scheduler.thresholds = 13,25,50\n",
      "yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage = false\n",
      "ipc.client.kill.max = 10\n",
      "mapreduce.job.committer.setup.cleanup.needed = true\n",
      "fs.s3a.select.input.csv.comment.marker = #\n",
      "yarn.nodemanager.localizer.cache.target-size-mb = 10240\n",
      "yarn.resourcemanager.admin.client.thread-count = 1\n",
      "fs.ftp.impl = org.apache.hadoop.fs.ftp.FTPFileSystem\n",
      "hadoop.security.group.mapping.ldap.connection.timeout.ms = 60000\n",
      "yarn.timeline-service.store-class = org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore\n",
      "yarn.resourcemanager.nm-container-queuing.queue-limit-stdev = 1.0f\n",
      "hadoop.tmp.dir = /tmp/hadoop-${user.name}\n",
      "yarn.resourcemanager.zk-appid-node.split-index = 0\n",
      "fs.s3a.etag.checksum.enabled = false\n",
      "hadoop.security.kms.client.failover.sleep.base.millis = 100\n",
      "yarn.node-labels.configuration-type = centralized\n",
      "fs.s3a.retry.interval = 500ms\n",
      "yarn.timeline-service.ttl-ms = 604800000\n",
      "mapreduce.task.exit.timeout.check-interval-ms = 20000\n",
      "hadoop.http.idle_timeout.ms = 60000\n",
      "mapreduce.map.speculative = true\n",
      "yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms = 1000\n",
      "yarn.timeline-service.recovery.enabled = false\n",
      "yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed = false\n",
      "yarn.nodemanager.recovery.dir = ${hadoop.tmp.dir}/yarn-nm-recovery\n",
      "mapreduce.job.counters.max = 120\n",
      "fs.s3a.select.errors.include.sql = false\n",
      "yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms = 20\n",
      "yarn.webapp.ui2.enable = false\n",
      "yarn.nodemanager.elastic-memory-control.oom-handler = org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler\n",
      "mapreduce.map.log.level = INFO\n",
      "yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms = 1000\n",
      "hadoop.zk.timeout-ms = 10000\n",
      "ha.health-monitor.check-interval.ms = 1000\n",
      "yarn.resourcemanager.fs.state-store.retry-interval-ms = 1000\n",
      "mapreduce.output.fileoutputformat.compress = false\n",
      "yarn.sharedcache.store.in-memory.staleness-period-mins = 10080\n",
      "yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep = 100\n",
      "fs.AbstractFileSystem.har.impl = org.apache.hadoop.fs.HarFs\n",
      "hadoop.security.group.mapping.providers.combined = true\n",
      "mapreduce.job.running.map.limit = 0\n",
      "mapreduce.reduce.input.buffer.percent = 0.0\n",
      "yarn.nodemanager.webapp.address = ${yarn.nodemanager.hostname}:8042\n",
      "yarn.resourcemanager.placement-constraints.scheduler.pool-size = 1\n",
      "fs.s3a.multipart.size = 64M\n",
      "yarn.app.mapreduce.am.job.committer.commit-window = 10000\n",
      "yarn.timeline-service.webapp.rest-csrf.enabled = false\n",
      "yarn.timeline-service.reader.class = org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl\n",
      "yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled = false\n",
      "yarn.timeline-service.writer.class = org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl\n",
      "mapreduce.ifile.readahead = true\n",
      "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin = org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin\n",
      "yarn.timeline-service.entity-group-fs-store.summary-store = org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore\n",
      "fs.s3a.s3guard.ddb.table.create = false\n",
      "fs.s3a.select.input.csv.field.delimiter = ,\n",
      "fs.s3a.socket.recv.buffer = 8192\n",
      "mapreduce.output.fileoutputformat.compress.codec = org.apache.hadoop.io.compress.DefaultCodec\n",
      "fs.AbstractFileSystem.gs.impl = com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\n",
      "fs.adl.impl = org.apache.hadoop.fs.adl.AdlFileSystem\n",
      "mapreduce.jobhistory.webapp.address = 0.0.0.0:19888\n",
      "yarn.sharedcache.store.in-memory.initial-delay-mins = 10\n",
      "mapreduce.job.local-fs.single-disk-limit.bytes = -1\n",
      "mapreduce.task.userlog.limit.kb = 0\n",
      "fs.s3a.connection.ssl.enabled = true\n",
      "yarn.router.rmadmin.interceptor-class.pipeline = org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor\n",
      "yarn.sharedcache.webapp.address = 0.0.0.0:8788\n",
      "ipc.server.max.connections = 0\n",
      "yarn.resourcemanager.rm.container-allocation.expiry-interval-ms = 600000\n",
      "yarn.resourcemanager.proxy.connection.timeout = 60000\n",
      "yarn.app.mapreduce.am.resource.mb = 1536\n",
      "hadoop.security.groups.cache.secs = 300\n",
      "mapreduce.shuffle.transfer.buffer.size = 131072\n",
      "hadoop.security.group.mapping.ldap.directory.search.timeout = 10000\n",
      "fs.s3a.committer.threads = 8\n",
      "yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts = 3\n",
      "yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs = 3600\n",
      "yarn.scheduler.maximum-allocation-vcores = 4\n",
      "yarn.nodemanager.sleep-delay-before-sigkill.ms = 250\n",
      "fs.AbstractFileSystem.abfs.impl = org.apache.hadoop.fs.azurebfs.Abfs\n",
      "mapreduce.job.acl-modify-job =  \n",
      "fs.automatic.close = true\n",
      "fs.azure.sas.expiry.period = 90d\n",
      "yarn.resourcemanager.activities-manager.app-activities.ttl-ms = 600000\n",
      "hadoop.security.groups.cache.background.reload.threads = 3\n",
      "yarn.resourcemanager.delegation-token-renewer.thread-timeout = 60s\n",
      "mapreduce.input.fileinputformat.list-status.num-threads = 1\n",
      "hadoop.security.group.mapping.ldap.posix.attr.gid.name = gidNumber\n",
      "yarn.nodemanager.container-log-monitor.dir-size-limit-bytes = 1000000000\n",
      "yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled = true\n",
      "yarn.nodemanager.health-checker.run-before-startup = false\n",
      "mapreduce.shuffle.listen.queue.size = 128\n",
      "mapreduce.jobhistory.intermediate-done-dir = ${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate\n",
      "mapreduce.client.libjars.wildcard = true\n",
      "yarn.nodemanager.recovery.compaction-interval-secs = 3600\n",
      "mapreduce.reduce.shuffle.input.buffer.percent = 0.70\n",
      "yarn.http.policy = HTTP_ONLY\n",
      "mapreduce.map.maxattempts = 4\n",
      "io.serializations = org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization\n",
      "hadoop.security.groups.cache.warn.after.ms = 5000\n",
      "yarn.nodemanager.webapp.rest-csrf.custom-header = X-XSRF-Header\n",
      "hadoop.http.cross-origin.allowed-methods = GET,POST,HEAD\n",
      "yarn.node-labels.fs-store.impl.class = org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore\n",
      "mapreduce.jobhistory.webapp.rest-csrf.enabled = false\n",
      "hadoop.zk.acl = world:anyone:rwcda\n",
      "yarn.nodemanager.container.stderr.pattern = {*stderr*,*STDERR*}\n",
      "mapreduce.cluster.local.dir = ${hadoop.tmp.dir}/mapred/local\n",
      "ipc.[port_number].cost-provider.impl = org.apache.hadoop.ipc.DefaultCostProvider\n",
      "hadoop.kerberos.kinit.command = kinit\n",
      "fs.viewfs.overload.scheme.target.abfss.impl = org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem\n",
      "mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed = true\n",
      "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch = false\n",
      "yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms = 60000\n",
      "fs.viewfs.rename.strategy = SAME_MOUNTPOINT\n",
      "ipc.client.connect.max.retries.on.timeouts = 45\n",
      "fs.client.resolve.topology.enabled = false\n",
      "yarn.resourcemanager.node-labels.provider.fetch-interval-ms = 1800000\n",
      "yarn.nodemanager.container-metrics.enable = true\n",
      "mapreduce.job.map.output.collector.class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "fs.s3a.fast.upload.buffer = disk\n",
      "ha.health-monitor.connect-retry-interval.ms = 1000\n",
      "io.mapfile.bloom.size = 1048576\n",
      "fs.ftp.data.connection.mode = ACTIVE_LOCAL_DATA_CONNECTION_MODE\n",
      "hadoop.security.kms.client.authentication.retry-count = 1\n",
      "yarn.nodemanager.runtime.linux.runc.image-toplevel-dir = /runc-root\n",
      "yarn.nodemanager.containers-launcher.class = org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher\n",
      "fs.swift.impl = org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem\n",
      "yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore = GET,OPTIONS,HEAD\n",
      "mapreduce.job.max.map = -1\n",
      "yarn.app.mapreduce.shuffle.log.backups = 0\n",
      "ftp.blocksize = 67108864\n",
      "yarn.resourcemanager.scheduler.monitor.enable = false\n",
      "yarn.sharedcache.nm.uploader.thread-count = 20\n",
      "yarn.nodemanager.elastic-memory-control.enabled = false\n",
      "yarn.log-aggregation.debug.filesize = 104857600\n",
      "yarn.app.mapreduce.client.job.retry-interval = 2000\n",
      "fs.s3a.select.output.csv.quote.character = \"\n",
      "mapreduce.task.stuck.timeout-ms = 600000\n",
      "yarn.scheduler.configuration.store.max-logs = 1000\n",
      "hadoop.security.authorization = false\n",
      "yarn.timeline-service.version = 1.0f\n",
      "fs.har.impl.disable.cache = true\n",
      "yarn.am.liveness-monitor.expiry-interval-ms = 600000\n",
      "mapreduce.job.reduce.slowstart.completedmaps = 0.05\n",
      "yarn.timeline-service.leveldb-timeline-store.path = ${hadoop.tmp.dir}/yarn/timeline\n",
      "mapreduce.jobhistory.minicluster.fixed.ports = false\n",
      "yarn.resourcemanager.delegation.token.max-lifetime = 604800000\n",
      "yarn.resourcemanager.ha.automatic-failover.enabled = true\n",
      "hadoop.security.group.mapping.ldap.conversion.rule = none\n",
      "io.mapfile.bloom.error.rate = 0.005\n",
      "yarn.resourcemanager.store.class = org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\n",
      "yarn.nodemanager.webapp.rest-csrf.enabled = false\n",
      "yarn.timeline-service.leveldb-state-store.path = ${hadoop.tmp.dir}/yarn/timeline\n",
      "fs.s3a.committer.staging.unique-filenames = true\n",
      "yarn.scheduler.configuration.zk-store.parent-path = /confstore\n",
      "yarn.nodemanager.container-executor.exit-code-file.timeout-ms = 2000\n",
      "ipc.[port_number].backoff.enable = false\n",
      "yarn.nodemanager.container-executor.class = org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor\n",
      "yarn.timeline-service.writer.flush-interval-seconds = 60\n",
      "yarn.app.mapreduce.shuffle.log.separate = true\n",
      "hadoop.security.kms.client.encrypted.key.cache.low-watermark = 0.3f\n",
      "hadoop.user.group.static.mapping.overrides = dr.who=;\n",
      "fs.s3a.retry.throttle.interval = 100ms\n",
      "mapreduce.jobhistory.webapp.rest-csrf.custom-header = X-XSRF-Header\n",
      "yarn.nodemanager.amrmproxy.address = 0.0.0.0:8049\n",
      "yarn.webapp.xfs-filter.enabled = true\n",
      "yarn.resourcemanager.submission-preprocessor.enabled = false\n",
      "hadoop.system.tags = YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n",
      "      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL\n",
      "yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache = 10\n",
      "yarn.nodemanager.numa-awareness.numactl.cmd = /usr/bin/numactl\n",
      "yarn.nodemanager.collector-service.thread-count = 5\n",
      "yarn.nodemanager.runtime.linux.docker.capabilities = CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE\n",
      "yarn.nodemanager.distributed-scheduling.enabled = false\n",
      "ipc.client.fallback-to-simple-auth-allowed = false\n",
      "yarn.minicluster.fixed.ports = false\n",
      "yarn.nodemanager.remote-app-log-dir = /tmp/logs\n",
      "yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size = 500\n",
      "yarn.timeline-service.entity-group-fs-store.scan-interval-seconds = 60\n",
      "yarn.nodemanager.resource.percentage-physical-cpu-limit = 100\n",
      "fs.s3a.s3guard.cli.prune.age = 86400000\n",
      "hadoop.jetty.logs.serve.aliases = true\n",
      "yarn.timeline-service.app-aggregation-interval-secs = 15\n",
      "mapreduce.jobhistory.admin.acl = *\n",
      "mapreduce.job.reducer.unconditional-preempt.delay.sec = 300\n",
      "yarn.app.mapreduce.am.hard-kill-timeout-ms = 10000\n",
      "yarn.resourcemanager.node-removal-untracked.timeout-ms = 60000\n",
      "mapreduce.jobhistory.recovery.enable = false\n",
      "yarn.resourcemanager.webapp.address = ${yarn.resourcemanager.hostname}:8088\n",
      "yarn.sharedcache.store.in-memory.check-period-mins = 720\n",
      "fs.s3a.aws.credentials.provider = \n",
      "    org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider,\n",
      "    org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider,\n",
      "    com.amazonaws.auth.EnvironmentVariableCredentialsProvider,\n",
      "    org.apache.hadoop.fs.s3a.auth.IAMInstanceCredentialsProvider\n",
      "  \n",
      "fs.df.interval = 60000\n",
      "yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class = org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin\n",
      "fs.s3a.assumed.role.session.duration = 30m\n",
      "mapreduce.job.cache.limit.max-single-resource-mb = 0\n",
      "yarn.timeline-service.enabled = false\n",
      "hadoop.http.cross-origin.allowed-headers = X-Requested-With,Content-Type,Accept,Origin\n",
      "mapreduce.task.profile = false\n",
      "yarn.router.webapp.address = 0.0.0.0:8089\n",
      "yarn.nodemanager.hostname = 0.0.0.0\n",
      "mapreduce.task.exit.timeout = 60000\n",
      "yarn.resourcemanager.nm-container-queuing.max-queue-length = 15\n",
      "mapreduce.job.token.tracking.ids.enabled = false\n",
      "fs.s3a.assumed.role.credentials.provider = org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\n",
      "fs.azure.authorization.caching.enable = true\n",
      "hadoop.security.kms.client.failover.sleep.max.millis = 2000\n",
      "fs.s3a.committer.abort.pending.uploads = true\n",
      "yarn.resourcemanager.webapp.rest-csrf.custom-header = X-XSRF-Header\n",
      "yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms = 100\n",
      "mapreduce.jobhistory.move.thread-count = 3\n",
      "fs.AbstractFileSystem.hdfs.impl = org.apache.hadoop.fs.Hdfs\n",
      "yarn.nodemanager.container-localizer.log.level = INFO\n",
      "hadoop.http.filter.initializers = org.apache.hadoop.http.lib.StaticUserWebFilter\n",
      "yarn.timeline-service.http-authentication.simple.anonymous.allowed = true\n",
      "yarn.webapp.filter-invalid-xml-chars = false\n",
      "yarn.nodemanager.runtime.linux.docker.allowed-container-networks = host,none,bridge\n",
      "yarn.sharedcache.client-server.thread-count = 50\n",
      "yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin = org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin\n",
      "fs.s3a.s3guard.ddb.max.retries = 9\n",
      "fs.s3a.committer.magic.enabled = true\n",
      "yarn.resourcemanager.resource-tracker.address = ${yarn.resourcemanager.hostname}:8031\n",
      "yarn.scheduler.configuration.max.version = 100\n",
      "mapreduce.jobhistory.jobname.limit = 50\n",
      "yarn.dispatcher.print-events-info.threshold = 5000\n",
      "rpc.metrics.quantile.enable = false\n",
      "yarn.federation.subcluster-resolver.class = org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl\n",
      "mapreduce.task.timeout = 600000\n",
      "yarn.nodemanager.resource.memory-mb = -1\n",
      "yarn.nodemanager.disk-health-checker.min-healthy-disks = 0.25\n",
      "yarn.nodemanager.container-log-monitor.total-size-limit-bytes = 10000000000\n",
      "mapreduce.fileoutputcommitter.algorithm.version = 1\n",
      "mapreduce.framework.name = local\n",
      "yarn.router.clientrm.interceptor-class.pipeline = org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor\n",
      "yarn.resourcemanager.system-metrics-publisher.enabled = false\n",
      "yarn.sharedcache.nested-level = 3\n",
      "hadoop.caller.context.signature.max.size = 40\n",
      "fs.s3a.connection.timeout = 200000\n",
      "hadoop.security.dns.log-slow-lookups.enabled = false\n",
      "mapreduce.jobhistory.webapp.https.address = 0.0.0.0:19890\n",
      "fs.s3a.s3guard.ddb.table.capacity.read = 0\n",
      "file.client-write-packet-size = 65536\n",
      "yarn.nodemanager.pluggable-device-framework.enabled = false\n",
      "ipc.client.ping = true\n",
      "fs.s3a.change.detection.source = etag\n",
      "yarn.resourcemanager.delayed.delegation-token.removal-interval-ms = 30000\n",
      "mapreduce.job.encrypted-intermediate-data = false\n",
      "yarn.nodemanager.webapp.cross-origin.enabled = false\n",
      "yarn.nodemanager.opportunistic-containers-use-pause-for-preemption = false\n",
      "yarn.minicluster.control-resource-monitoring = false\n",
      "yarn.resourcemanager.resource-tracker.nm.ip-hostname-check = false\n",
      "yarn.resourcemanager.fs.state-store.num-retries = 0\n",
      "hadoop.ssl.require.client.cert = false\n",
      "hadoop.security.uid.cache.secs = 14400\n",
      "mapreduce.jobhistory.keytab = /etc/security/keytab/jhs.service.keytab\n",
      "yarn.resourcemanager.ha.automatic-failover.zk-base-path = /yarn-leader-election\n",
      "yarn.intermediate-data-encryption.enable = false\n",
      "mapreduce.job.speculative.speculative-cap-running-tasks = 0.1\n",
      "yarn.system-metrics-publisher.enabled = false\n",
      "yarn.timeline-service.entity-group-fs-store.app-cache-size = 10\n",
      "hadoop.tags.system = YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n",
      "      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL\n",
      "fs.AbstractFileSystem.s3a.impl = org.apache.hadoop.fs.s3a.S3A\n",
      "yarn.client.load.resource-types.from-server = false\n",
      "ipc.client.tcpnodelay = true\n",
      "yarn.resourcemanager.metrics.runtime.buckets = 60,300,1440\n",
      "yarn.client.application-client-protocol.poll-timeout-ms = -1\n",
      "io.map.index.skip = 0\n",
      "mapreduce.job.sharedcache.mode = disabled\n",
      "mapreduce.job.hdfs-servers = ${fs.defaultFS}\n",
      "yarn.resourcemanager.epoch.range = 0\n",
      "mapreduce.map.output.compress = false\n",
      "hadoop.security.token.service.use_ip = true\n",
      "hadoop.security.kms.client.encrypted.key.cache.num.refill.threads = 2\n",
      "mapreduce.task.merge.progress.records = 10000\n",
      "yarn.nodemanager.aux-services.mapreduce_shuffle.class = org.apache.hadoop.mapred.ShuffleHandler\n",
      "hadoop.security.group.mapping.ldap.num.attempts.before.failover = 3\n",
      "tfile.fs.output.buffer.size = 262144\n",
      "fs.du.interval = 600000\n",
      "hadoop.zk.retry-interval-ms = 1000\n",
      "yarn.sharedcache.uploader.server.address = 0.0.0.0:8046\n",
      "fs.s3a.socket.send.buffer = 8192\n",
      "hadoop.registry.zk.quorum = localhost:2181\n",
      "mapreduce.jvm.system-properties-to-log = os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name\n",
      "hadoop.http.cross-origin.allowed-origins = *\n",
      "hadoop.registry.system.acls = sasl:yarn@, sasl:mapred@, sasl:hdfs@\n",
      "mapreduce.job.encrypted-intermediate-data.buffer.kb = 128\n",
      "yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint = http://localhost:3476/v1.0/docker/cli\n",
      "yarn.resourcemanager.webapp.xfs-filter.xframe-options = SAMEORIGIN\n",
      "mapreduce.task.profile.reduce.params = ${mapreduce.task.profile.params}\n",
      "mapreduce.reduce.memory.mb = -1\n",
      "hadoop.http.authentication.kerberos.principal = HTTP/_HOST@LOCALHOST\n",
      "hadoop.caller.context.enabled = false\n",
      "yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor = 1.0\n",
      "yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb = 0\n",
      "hadoop.security.sensitive-config-keys = \n",
      "      secret$\n",
      "      password$\n",
      "      ssl.keystore.pass$\n",
      "      fs.s3a.server-side-encryption.key\n",
      "      fs.s3a.*.server-side-encryption.key\n",
      "      fs.s3a.encryption.algorithm\n",
      "      fs.s3a.encryption.key\n",
      "      fs.s3a.secret.key\n",
      "      fs.s3a.*.secret.key\n",
      "      fs.s3a.session.key\n",
      "      fs.s3a.*.session.key\n",
      "      fs.s3a.session.token\n",
      "      fs.s3a.*.session.token\n",
      "      fs.azure.account.key.*\n",
      "      fs.azure.oauth2.*\n",
      "      fs.adl.oauth2.*\n",
      "      fs.gs.encryption.*\n",
      "      fs.gs.proxy.*\n",
      "      fs.gs.auth.*\n",
      "      credential$\n",
      "      oauth.*secret\n",
      "      oauth.*password\n",
      "      oauth.*token\n",
      "      hadoop.security.sensitive-config-keys\n",
      "  \n",
      "mapreduce.client.completion.pollinterval = 5000\n",
      "yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds = 60\n",
      "hadoop.security.group.mapping.ldap.read.timeout.ms = 60000\n",
      "hadoop.http.logs.enabled = true\n",
      "yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory = 10\n",
      "yarn.resourcemanager.webapp.https.address = ${yarn.resourcemanager.hostname}:8090\n",
      "yarn.resourcemanager.activities-manager.app-activities.max-queue-length = 100\n",
      "fs.s3a.retry.throttle.limit = 20\n",
      "yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed = false\n",
      "hadoop.domainname.resolver.impl = org.apache.hadoop.net.DNSDomainNameResolver\n",
      "mapreduce.job.cache.limit.max-resources = 0\n",
      "fs.s3a.endpoint = s3.amazonaws.com\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Local file system conf\n",
    "\n",
    "In spark local mode, spark writes data on the local file system. We\n",
    "\n",
    "\n",
    "```python\n",
    "hadoop_conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "\n",
    "# Use local filesystem explicitly (default for file:// but override possible)\n",
    "hadoop_conf.set(\"fs.defaultFS\", \"file:///\")\n",
    "hadoop_conf.set(\"fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\")\n",
    "# Use larger I/O buffer (default is 4 KB — too small for bulk)\n",
    "hadoop_conf.set(\"io.file.buffer.size\", \"131072\")  # 128 KB\n",
    "\n",
    "# Temp / staging directories\n",
    "hadoop_conf.set(\"hadoop.tmp.dir\", \"/tmp/hadoop_spark_tmp\")\n",
    "hadoop_conf.set(\"mapreduce.cluster.local.dir\", \"/tmp/spark_local_dir\")\n",
    "\n",
    "# Replication factor not used in local mode, but still prevent unnecessary checks\n",
    "hadoop_conf.set(\"dfs.replication\", \"1\")\n",
    "\n",
    "# Enable fast compression\n",
    "hadoop_conf.set(\"mapreduce.output.fileoutputformat.compress\", \"true\")\n",
    "hadoop_conf.set(\"mapreduce.output.fileoutputformat.compress.codec\",\n",
    "         \"org.apache.hadoop.io.compress.SnappyCodec\")\n",
    "```\n"
   ],
   "id": "1c662ef6f8fc629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:09:23.681477Z",
     "start_time": "2025-07-29T08:09:23.673449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get current\n",
    "print(hadoop_conf.get(\"fs.file.impl\"))"
   ],
   "id": "14a338cf01a73d8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:11:42.641613Z",
     "start_time": "2025-07-29T08:11:42.629888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the default value is 65536 (8kb)\n",
    "hadoop_conf.get(\"io.file.buffer.size\")"
   ],
   "id": "d49a4ef5c9ad4743",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65536'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:24:43.844109Z",
     "start_time": "2025-07-29T09:24:43.835156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This folder will be used to store temp file for Hadoop I/O, if the file format is Hadoop-based formats like .orc, .avro\n",
    "hadoop_conf.get(\"hadoop.tmp.dir\")"
   ],
   "id": "cecc3bcdf22a0192",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd1/tmp_hadoop'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ed8e2e73c09079d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
